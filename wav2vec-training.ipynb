{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fded32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:56:07.362439Z",
     "iopub.status.busy": "2022-02-27T14:56:07.359602Z",
     "iopub.status.idle": "2022-02-27T14:57:26.992166Z",
     "shell.execute_reply": "2022-02-27T14:57:26.991542Z",
     "shell.execute_reply.started": "2022-02-27T14:50:45.497573Z"
    },
    "papermill": {
     "duration": 79.689625,
     "end_time": "2022-02-27T14:57:26.992327",
     "exception": false,
     "start_time": "2022-02-27T14:56:07.302702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_metric_learning\r\n",
      "  Downloading pytorch_metric_learning-1.1.2-py3-none-any.whl (106 kB)\r\n",
      "     |████████████████████████████████| 106 kB 901 kB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pytorch_metric_learning) (0.10.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch_metric_learning) (1.20.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pytorch_metric_learning) (0.23.2)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_metric_learning) (1.9.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch_metric_learning) (4.62.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->pytorch_metric_learning) (4.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pytorch_metric_learning) (3.0.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pytorch_metric_learning) (1.7.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pytorch_metric_learning) (1.1.0)\r\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->pytorch_metric_learning) (8.2.0)\r\n",
      "Installing collected packages: pytorch-metric-learning\r\n",
      "Successfully installed pytorch-metric-learning-1.1.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (0.9.1)\r\n",
      "Collecting torchaudio\r\n",
      "  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 879 kB/s            \r\n",
      "\u001b[?25hCollecting torch==1.10.2\r\n",
      "  Downloading torch-1.10.2-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\r\n",
      "     |████████████████████████████████| 881.9 MB 1.4 kB/s             \r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.10.2->torchaudio) (4.0.1)\r\n",
      "Installing collected packages: torch, torchaudio\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.9.1\r\n",
      "    Uninstalling torch-1.9.1:\r\n",
      "      Successfully uninstalled torch-1.9.1\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 0.9.1\r\n",
      "    Uninstalling torchaudio-0.9.1:\r\n",
      "      Successfully uninstalled torchaudio-0.9.1\r\n",
      "Successfully installed torch-1.10.2 torchaudio-0.10.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_metric_learning\n",
    "!pip install -U torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc73cfca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:27.649719Z",
     "iopub.status.busy": "2022-02-27T14:57:27.648857Z",
     "iopub.status.idle": "2022-02-27T14:57:28.539161Z",
     "shell.execute_reply": "2022-02-27T14:57:28.538156Z",
     "shell.execute_reply.started": "2022-02-27T14:52:07.580615Z"
    },
    "papermill": {
     "duration": 1.220399,
     "end_time": "2022-02-27T14:57:28.539294",
     "exception": false,
     "start_time": "2022-02-27T14:57:27.318895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee86b60c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:29.223762Z",
     "iopub.status.busy": "2022-02-27T14:57:29.222835Z",
     "iopub.status.idle": "2022-02-27T14:57:30.178802Z",
     "shell.execute_reply": "2022-02-27T14:57:30.178312Z",
     "shell.execute_reply.started": "2022-02-27T14:52:08.461886Z"
    },
    "papermill": {
     "duration": 1.306766,
     "end_time": "2022-02-27T14:57:30.178964",
     "exception": false,
     "start_time": "2022-02-27T14:57:28.872198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchaudio\n",
    "from pytorch_metric_learning import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b0744c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:30.856135Z",
     "iopub.status.busy": "2022-02-27T14:57:30.855323Z",
     "iopub.status.idle": "2022-02-27T14:57:30.858179Z",
     "shell.execute_reply": "2022-02-27T14:57:30.857720Z",
     "shell.execute_reply.started": "2022-02-27T14:52:09.388642Z"
    },
    "papermill": {
     "duration": 0.344773,
     "end_time": "2022-02-27T14:57:30.858303",
     "exception": false,
     "start_time": "2022-02-27T14:57:30.513530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427f1d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:31.545153Z",
     "iopub.status.busy": "2022-02-27T14:57:31.544154Z",
     "iopub.status.idle": "2022-02-27T14:57:53.255281Z",
     "shell.execute_reply": "2022-02-27T14:57:53.256814Z",
     "shell.execute_reply.started": "2022-02-27T14:52:09.397114Z"
    },
    "papermill": {
     "duration": 22.049945,
     "end_time": "2022-02-27T14:57:53.257056",
     "exception": false,
     "start_time": "2022-02-27T14:57:31.207111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2265dd48984026a1d6669d83803297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/360M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wav2vec2 = bundle.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbace471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:53.999147Z",
     "iopub.status.busy": "2022-02-27T14:57:53.998276Z",
     "iopub.status.idle": "2022-02-27T14:57:54.000704Z",
     "shell.execute_reply": "2022-02-27T14:57:54.000299Z",
     "shell.execute_reply.started": "2022-02-27T14:52:30.704248Z"
    },
    "papermill": {
     "duration": 0.329587,
     "end_time": "2022-02-27T14:57:54.000820",
     "exception": false,
     "start_time": "2022-02-27T14:57:53.671233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav2vec2.encoder.transformer.layers = wav2vec2.encoder.transformer.layers[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dc1246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:54.693966Z",
     "iopub.status.busy": "2022-02-27T14:57:54.693248Z",
     "iopub.status.idle": "2022-02-27T14:57:54.696036Z",
     "shell.execute_reply": "2022-02-27T14:57:54.696431Z",
     "shell.execute_reply.started": "2022-02-27T14:52:30.714280Z"
    },
    "papermill": {
     "duration": 0.379094,
     "end_time": "2022-02-27T14:57:54.696577",
     "exception": false,
     "start_time": "2022-02-27T14:57:54.317483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '/kaggle/input/classification-of-short-noisy-audio-speech/hackaton_ds/train/'\n",
    "batch_size = 64\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1898a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:55.349295Z",
     "iopub.status.busy": "2022-02-27T14:57:55.348408Z",
     "iopub.status.idle": "2022-02-27T14:57:55.350821Z",
     "shell.execute_reply": "2022-02-27T14:57:55.350409Z",
     "shell.execute_reply.started": "2022-02-27T14:52:30.769191Z"
    },
    "papermill": {
     "duration": 0.335997,
     "end_time": "2022-02-27T14:57:55.350969",
     "exception": false,
     "start_time": "2022-02-27T14:57:55.014972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommandDataset(Dataset):\n",
    "\n",
    "    def __init__(self, meta, root_dir, sample_rate, labelmap):\n",
    "        self.meta = meta\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.labelmap = labelmap\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        file_name = self.meta['path'].iloc[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_name)\n",
    "        \n",
    "        if random.randint(0, 1):\n",
    "        \n",
    "            effects = [\n",
    "              [\"speed\", str(np.random.random() + 0.5)],  # reduce the speed\n",
    "                                 # This only changes sample rate, so it is necessary to\n",
    "                                 # add `rate` effect with original sample rate after this.\n",
    "              [\"rate\", f\"{sample_rate}\"],\n",
    "            ]\n",
    "\n",
    "            # Apply effects\n",
    "            waveform, sample_rate = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                waveform, sample_rate, effects)\n",
    "            \n",
    "        if random.randint(0, 1):\n",
    "        \n",
    "            effects = [\n",
    "              [\"rate\", f\"{sample_rate}\"],\n",
    "              [\"reverb\", \"-w\"],  # Reverbration gives some dramatic feeling\n",
    "            ]\n",
    "\n",
    "            # Apply effects\n",
    "            waveform, sample_rate = torchaudio.sox_effects.apply_effects_tensor(\n",
    "                waveform, sample_rate, effects)\n",
    "        \n",
    "        waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)#[:, :10**5]\n",
    "        waveform = torch.nn.functional.pad(waveform, (16000-waveform.shape[1], 0))[0]\n",
    "            \n",
    "        label = self.meta['label'].iloc[idx]\n",
    "\n",
    "        return waveform, self.labelmap[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa12d58d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:55.998243Z",
     "iopub.status.busy": "2022-02-27T14:57:55.997290Z",
     "iopub.status.idle": "2022-02-27T14:57:55.998835Z",
     "shell.execute_reply": "2022-02-27T14:57:55.999258Z",
     "shell.execute_reply.started": "2022-02-27T14:52:30.782332Z"
    },
    "papermill": {
     "duration": 0.329002,
     "end_time": "2022-02-27T14:57:55.999393",
     "exception": false,
     "start_time": "2022-02-27T14:57:55.670391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'yes': 0, \n",
    "    'no': 1, \n",
    "    'up': 2, \n",
    "    'down': 3, \n",
    "    'left': 4, \n",
    "    'right': 5, \n",
    "    'on': 6, \n",
    "    'off': 7, \n",
    "    'stop': 8, \n",
    "    'go': 9, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9816f94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:57:56.699565Z",
     "iopub.status.busy": "2022-02-27T14:57:56.698743Z",
     "iopub.status.idle": "2022-02-27T14:58:30.804509Z",
     "shell.execute_reply": "2022-02-27T14:58:30.804038Z",
     "shell.execute_reply.started": "2022-02-27T14:52:30.792531Z"
    },
    "papermill": {
     "duration": 34.454684,
     "end_time": "2022-02-27T14:58:30.804653",
     "exception": false,
     "start_time": "2022-02-27T14:57:56.349969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([\n",
    "    {'label': i[0].split('/')[-1], 'path': i[0] + '/' + j}\n",
    "    for i in os.walk(root_dir)\n",
    "    for j in i[2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ff2242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:58:31.525741Z",
     "iopub.status.busy": "2022-02-27T14:58:31.525186Z",
     "iopub.status.idle": "2022-02-27T14:58:31.530004Z",
     "shell.execute_reply": "2022-02-27T14:58:31.529569Z",
     "shell.execute_reply.started": "2022-02-27T14:53:40.799314Z"
    },
    "papermill": {
     "duration": 0.388321,
     "end_time": "2022-02-27T14:58:31.530132",
     "exception": false,
     "start_time": "2022-02-27T14:58:31.141811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop     8925\n",
       "yes      8910\n",
       "no       8905\n",
       "up       8905\n",
       "go       8895\n",
       "right    8875\n",
       "on       8875\n",
       "down     8845\n",
       "off      8835\n",
       "left     8820\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4789e39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:58:32.471363Z",
     "iopub.status.busy": "2022-02-27T14:58:32.470489Z",
     "iopub.status.idle": "2022-02-27T14:58:32.492115Z",
     "shell.execute_reply": "2022-02-27T14:58:32.491653Z",
     "shell.execute_reply.started": "2022-02-27T14:53:40.837082Z"
    },
    "papermill": {
     "duration": 0.623615,
     "end_time": "2022-02-27T14:58:32.492246",
     "exception": false,
     "start_time": "2022-02-27T14:58:31.868631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(data, data['label'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff5a9ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:58:33.146666Z",
     "iopub.status.busy": "2022-02-27T14:58:33.145848Z",
     "iopub.status.idle": "2022-02-27T14:58:33.149156Z",
     "shell.execute_reply": "2022-02-27T14:58:33.149532Z",
     "shell.execute_reply.started": "2022-02-27T14:53:40.861847Z"
    },
    "papermill": {
     "duration": 0.338633,
     "end_time": "2022-02-27T14:58:33.149674",
     "exception": false,
     "start_time": "2022-02-27T14:58:32.811041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CommandDataset(meta=train, root_dir=root_dir, sample_rate=bundle.sample_rate, labelmap=labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12)\n",
    "\n",
    "val_dataset = CommandDataset(meta=val, root_dir=root_dir, sample_rate=bundle.sample_rate, labelmap=labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6703fa2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:58:33.797768Z",
     "iopub.status.busy": "2022-02-27T14:58:33.797153Z",
     "iopub.status.idle": "2022-02-27T14:58:33.800126Z",
     "shell.execute_reply": "2022-02-27T14:58:33.799663Z",
     "shell.execute_reply.started": "2022-02-27T14:53:40.875880Z"
    },
    "papermill": {
     "duration": 0.332887,
     "end_time": "2022-02-27T14:58:33.800245",
     "exception": false,
     "start_time": "2022-02-27T14:58:33.467358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommandClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(CommandClassifier, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.linear = nn.Linear(768, len(labels))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        features = self.get_embeddings(X)\n",
    "        logits = self.linear(features)\n",
    "        return logits\n",
    "    \n",
    "    def get_embeddings(self, X):\n",
    "        embeddings = self.feature_extractor(X)[0].mean(axis=1)\n",
    "        return nn.functional.normalize(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d5cd6",
   "metadata": {
    "papermill": {
     "duration": 0.320533,
     "end_time": "2022-02-27T14:58:34.437923",
     "exception": false,
     "start_time": "2022-02-27T14:58:34.117390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ae85a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:58:35.106759Z",
     "iopub.status.busy": "2022-02-27T14:58:35.106082Z",
     "iopub.status.idle": "2022-02-27T14:58:37.871307Z",
     "shell.execute_reply": "2022-02-27T14:58:37.870680Z",
     "shell.execute_reply.started": "2022-02-27T14:53:40.884509Z"
    },
    "papermill": {
     "duration": 3.103488,
     "end_time": "2022-02-27T14:58:37.871446",
     "exception": false,
     "start_time": "2022-02-27T14:58:34.767958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommandClassifier(\n",
       "  (feature_extractor): Wav2Vec2Model(\n",
       "    (feature_extractor): FeatureExtractor(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): ConvLayerBlock(\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "        )\n",
       "        (1): ConvLayerBlock(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (2): ConvLayerBlock(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (3): ConvLayerBlock(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (4): ConvLayerBlock(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (5): ConvLayerBlock(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (6): ConvLayerBlock(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (feature_projection): FeatureProjection(\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (pos_conv_embed): ConvolutionalPositionalEmbedding(\n",
       "          (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): EncoderLayer(\n",
       "            (attention): SelfAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): FeedForward(\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CommandClassifier(wav2vec2)\n",
    "#model.load_state_dict(torch.load('model.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd857ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:58:38.522501Z",
     "iopub.status.busy": "2022-02-27T14:58:38.521804Z",
     "iopub.status.idle": "2022-02-27T14:58:38.524866Z",
     "shell.execute_reply": "2022-02-27T14:58:38.524474Z",
     "shell.execute_reply.started": "2022-02-27T14:53:43.669000Z"
    },
    "papermill": {
     "duration": 0.329258,
     "end_time": "2022-02-27T14:58:38.525012",
     "exception": false,
     "start_time": "2022-02-27T14:58:38.195754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "lr = 0.00001\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "criterion = losses.ArcFaceLoss(len(labels), 768).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ec6cde6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T14:58:39.177339Z",
     "iopub.status.busy": "2022-02-27T14:58:39.176611Z",
     "iopub.status.idle": "2022-02-27T16:31:14.236532Z",
     "shell.execute_reply": "2022-02-27T16:31:14.076966Z"
    },
    "papermill": {
     "duration": 5555.395429,
     "end_time": "2022-02-27T16:31:14.236722",
     "exception": false,
     "start_time": "2022-02-27T14:58:38.841293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 1249/1249 [08:45<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 28.190096437501563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 139/139 [00:49<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 22.898601614314018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 1249/1249 [08:29<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 17.229438633227748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 139/139 [00:46<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 11.748464800471025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 1249/1249 [08:26<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 12.737000874274248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 139/139 [00:47<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 11.011330409015683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 1249/1249 [08:28<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.252048713861226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 139/139 [00:43<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 9.547991982466883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 1249/1249 [08:26<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.407116248189592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 139/139 [00:45<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 9.862160144092368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 1249/1249 [08:27<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.970041818481336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 139/139 [00:45<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 9.280216170729494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 1249/1249 [08:27<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.60015226154923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 139/139 [00:44<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 9.006933380373948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 1249/1249 [08:28<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.45025641217625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 139/139 [00:44<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 8.918710077409264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 1249/1249 [08:27<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.11135631604038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 139/139 [00:45<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 8.852062199613174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 1249/1249 [08:27<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 8.983869398184257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 139/139 [00:47<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 8.493209423778726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    model.train()     \n",
    "        \n",
    "    train_loss = []\n",
    "    for batch, targets in tqdm(train_dataloader, desc=f\"Epoch: {epoch}\"):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        predictions = model.get_embeddings(batch)\n",
    "\n",
    "        loss = criterion(predictions, targets) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    print('Training loss:', np.mean(train_loss))\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    val_loss = []\n",
    "    for batch, targets in tqdm(val_dataloader, desc=f\"Epoch: {epoch}\"):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            batch = batch.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            predictions = model.get_embeddings(batch)\n",
    "\n",
    "            loss = criterion(predictions, targets) \n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "    print('Val loss:', np.mean(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28abc41",
   "metadata": {
    "papermill": {
     "duration": 4.63253,
     "end_time": "2022-02-27T16:31:23.834296",
     "exception": false,
     "start_time": "2022-02-27T16:31:19.201766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc786f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T16:31:33.252134Z",
     "iopub.status.busy": "2022-02-27T16:31:33.250503Z",
     "iopub.status.idle": "2022-02-27T16:31:33.252696Z",
     "shell.execute_reply": "2022-02-27T16:31:33.253118Z"
    },
    "papermill": {
     "duration": 4.790994,
     "end_time": "2022-02-27T16:31:33.253254",
     "exception": false,
     "start_time": "2022-02-27T16:31:28.462260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "lr = 0.00001\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cb7f0a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T16:31:42.747866Z",
     "iopub.status.busy": "2022-02-27T16:31:42.747105Z",
     "iopub.status.idle": "2022-02-27T16:31:43.156794Z",
     "shell.execute_reply": "2022-02-27T16:31:43.156292Z"
    },
    "papermill": {
     "duration": 5.276814,
     "end_time": "2022-02-27T16:31:43.156942",
     "exception": false,
     "start_time": "2022-02-27T16:31:37.880128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "703da32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T16:31:53.134678Z",
     "iopub.status.busy": "2022-02-27T16:31:53.134101Z",
     "iopub.status.idle": "2022-02-27T16:31:56.742391Z",
     "shell.execute_reply": "2022-02-27T16:31:56.742827Z"
    },
    "papermill": {
     "duration": 8.410813,
     "end_time": "2022-02-27T16:31:56.743005",
     "exception": false,
     "start_time": "2022-02-27T16:31:48.332192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "148030cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T16:32:06.141464Z",
     "iopub.status.busy": "2022-02-27T16:32:06.140621Z",
     "iopub.status.idle": "2022-02-27T19:34:37.792284Z",
     "shell.execute_reply": "2022-02-27T19:34:37.791737Z"
    },
    "papermill": {
     "duration": 10956.506243,
     "end_time": "2022-02-27T19:34:37.792423",
     "exception": false,
     "start_time": "2022-02-27T16:32:01.286180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/1249 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "Epoch: 0: 100%|██████████| 1249/1249 [08:20<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8756983633323896 Train accuracy: 0.8143309431742813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 139/139 [00:47<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.6954565039641565 Val accuracy: 0.8396215790066449 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 1249/1249 [08:20<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.6208828876646544 Train accuracy: 0.8398218017544519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 139/139 [00:48<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.4995400536832193 Val accuracy: 0.8471674738146188 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 1249/1249 [08:20<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.4263253932575688 Train accuracy: 0.8452903855539288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 139/139 [00:45<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.3201172163160584 Val accuracy: 0.849194729136164 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 1249/1249 [08:21<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.2560138145955302 Train accuracy: 0.8494450075709227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 139/139 [00:44<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.1594499435356196 Val accuracy: 0.852573488005406 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 1249/1249 [08:21<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0975069085820568 Train accuracy: 0.8558271076572687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 139/139 [00:44<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.0177479540701393 Val accuracy: 0.8568532492397792 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 1249/1249 [08:22<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9613919271957024 Train accuracy: 0.8590181577004418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 139/139 [00:44<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.895346703289224 Val accuracy: 0.8570784998310621 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 1249/1249 [08:20<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8472239873331008 Train accuracy: 0.8625095418653251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 139/139 [00:44<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7906038666800629 Val accuracy: 0.8642865187521117 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 1249/1249 [08:20<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7501768259118327 Train accuracy: 0.8668894144736019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 139/139 [00:45<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7038744061970882 Val accuracy: 0.8665390246649397 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 1249/1249 [08:22<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.670487163136538 Train accuracy: 0.8695548798037817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 139/139 [00:45<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6418081826443295 Val accuracy: 0.867440027030071 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 1249/1249 [08:20<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6065149778743283 Train accuracy: 0.8721577755252719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 139/139 [00:47<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5799410686218481 Val accuracy: 0.8705935353080302 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 1249/1249 [08:19<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5581208644770355 Train accuracy: 0.8741349751598654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 139/139 [00:46<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.531025377752112 Val accuracy: 0.8739722941772722 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11: 100%|██████████| 1249/1249 [08:21<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5137503604062372 Train accuracy: 0.8782019997246937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11: 100%|██████████| 139/139 [00:45<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5097522113820632 Val accuracy: 0.8708187858993129 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12: 100%|██████████| 1249/1249 [08:20<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4807645382167245 Train accuracy: 0.8790654603246111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12: 100%|██████████| 139/139 [00:45<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4717001454006854 Val accuracy: 0.8783646807072869 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13: 100%|██████████| 1249/1249 [08:20<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.44786529895589294 Train accuracy: 0.8827946090025153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13: 100%|██████████| 139/139 [00:44<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4630011871135492 Val accuracy: 0.8732965424034238 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14: 100%|██████████| 1249/1249 [08:20<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4317512254389502 Train accuracy: 0.8834953886198396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14: 100%|██████████| 139/139 [00:44<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4285515723682994 Val accuracy: 0.8797161842549837 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15: 100%|██████████| 1249/1249 [08:21<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4109650780025533 Train accuracy: 0.8851972819761985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15: 100%|██████████| 139/139 [00:45<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.40832706878511166 Val accuracy: 0.8833201937155085 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16: 100%|██████████| 1249/1249 [08:20<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.39739994673704127 Train accuracy: 0.8864862159152057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16: 100%|██████████| 139/139 [00:44<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3991913080429859 Val accuracy: 0.8852348237414123 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17: 100%|██████████| 1249/1249 [08:21<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.38086933570446446 Train accuracy: 0.8889014028106268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17: 100%|██████████| 139/139 [00:45<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.39105070162591316 Val accuracy: 0.8843338213762811 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18: 100%|██████████| 1249/1249 [08:24<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3688080154890247 Train accuracy: 0.8916669795147101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18: 100%|██████████| 139/139 [00:45<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3951659688203455 Val accuracy: 0.8837706948980741 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19: 100%|██████████| 1249/1249 [08:25<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.35933089574830257 Train accuracy: 0.8936566930710416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19: 100%|██████████| 139/139 [00:45<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.39024318036415595 Val accuracy: 0.8823065660547359 "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    train_loss = []\n",
    "    train_predictions = []\n",
    "    train_targets = []\n",
    "    for batch, targets in tqdm(train_dataloader, desc=f\"Epoch: {epoch}\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        predictions = model(batch)\n",
    "        \n",
    "        loss = criterion(predictions, targets) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        train_predictions.extend(predictions.cpu().detach().numpy().argmax(axis=1))\n",
    "        train_targets.extend(targets.cpu().detach().numpy())\n",
    "        \n",
    "    \n",
    "    train_loss = np.mean(train_loss)\n",
    "    train_accuracy = accuracy_score(train_targets, train_predictions)\n",
    "    \n",
    "    print('Training loss:', train_loss, end=' ')\n",
    "    print('Train accuracy:', train_accuracy)\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    val_predictions = []\n",
    "    val_targets = []\n",
    "    val_loss = []\n",
    "    for batch, targets in tqdm(val_dataloader, desc=f\"Epoch: {epoch}\"):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            batch = batch.to(device)\n",
    "            targets = targets.to(device)\n",
    "            predictions = model(batch)\n",
    "            loss = criterion(predictions, targets) \n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            val_predictions.extend(predictions.cpu().numpy().argmax(axis=1))\n",
    "            val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = accuracy_score(val_targets, val_predictions)\n",
    "    \n",
    "    print('Val loss:', val_loss, end=' ')\n",
    "    print('Val accuracy:', val_accuracy, end=' ')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "    \n",
    "    writer.add_scalars(\n",
    "        'Accuracy', \n",
    "        {'train': train_accuracy, 'val': val_accuracy,}, \n",
    "        epoch\n",
    "    )\n",
    "    writer.add_scalars(\n",
    "        'Loss', \n",
    "        {'train': train_loss, 'val': val_loss,}, \n",
    "        epoch\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af25105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T19:35:05.032972Z",
     "iopub.status.busy": "2022-02-27T19:35:05.028933Z",
     "iopub.status.idle": "2022-02-27T19:35:05.038238Z",
     "shell.execute_reply": "2022-02-27T19:35:05.037483Z"
    },
    "papermill": {
     "duration": 13.517012,
     "end_time": "2022-02-27T19:35:05.038410",
     "exception": false,
     "start_time": "2022-02-27T19:34:51.521398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = '/kaggle/input/classification-of-short-noisy-audio-speech/hackaton_ds/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a561139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T19:35:32.193576Z",
     "iopub.status.busy": "2022-02-27T19:35:32.193028Z",
     "iopub.status.idle": "2022-02-27T19:45:15.498506Z",
     "shell.execute_reply": "2022-02-27T19:45:15.497988Z"
    },
    "papermill": {
     "duration": 596.81343,
     "end_time": "2022-02-27T19:45:15.498642",
     "exception": false,
     "start_time": "2022-02-27T19:35:18.685212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29620/29620 [09:42<00:00, 50.83it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "pred = []\n",
    "for i in tqdm(os.listdir(test_dir)):\n",
    "    \n",
    "    waveform, sample_rate = torchaudio.load(f'{test_dir}/{i}')\n",
    "    waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)#[:, :10**5]\n",
    "    waveform = torch.nn.functional.pad(waveform, (16000-waveform.shape[1], 0))[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(waveform.unsqueeze(0).to(device))[0].cpu()\n",
    "    \n",
    "    text_lab = list(labels.keys())[predictions.argmax()]\n",
    "    \n",
    "    pred.append({'id': i.replace('.wav', ''), 'category': text_lab})\n",
    "pred = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b211cdc",
   "metadata": {
    "papermill": {
     "duration": 15.465397,
     "end_time": "2022-02-27T19:45:46.161981",
     "exception": false,
     "start_time": "2022-02-27T19:45:30.696584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85cb35da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T19:46:16.987165Z",
     "iopub.status.busy": "2022-02-27T19:46:16.986506Z",
     "iopub.status.idle": "2022-02-27T19:46:17.054369Z",
     "shell.execute_reply": "2022-02-27T19:46:17.053927Z"
    },
    "papermill": {
     "duration": 15.54491,
     "end_time": "2022-02-27T19:46:17.054489",
     "exception": false,
     "start_time": "2022-02-27T19:46:01.509579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51440684",
   "metadata": {
    "papermill": {
     "duration": 15.600591,
     "end_time": "2022-02-27T19:46:47.651936",
     "exception": false,
     "start_time": "2022-02-27T19:46:32.051345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17466.484968,
   "end_time": "2022-02-27T19:47:05.447629",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T14:55:58.962661",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3da4a32f7760430fbc1fa62713a51389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "632fa2f2ee174c3285d70a805ab3846e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b676b06599c4658b0c2009264c590d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "74ecb02214be49269303fb53f1786259": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "873f949e0449434383ed0a06c11a79a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8aa07171d23a44f1ab1c3cd509631164": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_873f949e0449434383ed0a06c11a79a7",
       "max": 377565405.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3da4a32f7760430fbc1fa62713a51389",
       "value": 377565405.0
      }
     },
     "9d2265dd48984026a1d6669d83803297": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d4879a3bef7c416882ed0b01635ee05f",
        "IPY_MODEL_8aa07171d23a44f1ab1c3cd509631164",
        "IPY_MODEL_cae03035011841dca9b95c4688d0f5df"
       ],
       "layout": "IPY_MODEL_ef4561e06f964295b4098e85d8d7e1e2"
      }
     },
     "cae03035011841dca9b95c4688d0f5df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_632fa2f2ee174c3285d70a805ab3846e",
       "placeholder": "​",
       "style": "IPY_MODEL_db4788515e8b49ec88de2f40cb4b2749",
       "value": " 360M/360M [00:20&lt;00:00, 19.8MB/s]"
      }
     },
     "d4879a3bef7c416882ed0b01635ee05f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_74ecb02214be49269303fb53f1786259",
       "placeholder": "​",
       "style": "IPY_MODEL_6b676b06599c4658b0c2009264c590d1",
       "value": "100%"
      }
     },
     "db4788515e8b49ec88de2f40cb4b2749": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ef4561e06f964295b4098e85d8d7e1e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
